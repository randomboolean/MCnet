{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vle/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, Dense, Dropout, Flatten, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, CSVLogger\n",
    "\n",
    "from loader import load_20news\n",
    "from custom_layer import MonteCarloLRF, SeparableMonteCarloLRF, SeparableMonteCarloMaxPoolingV2, RandomLRF\n",
    "\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words=10000\n",
    "sparse=False\n",
    "remove_short_documents=True\n",
    "notebook = 'mcNet_top10k_temptative_42'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(input_shape, nb_classes), (X_train, X_test, Y_train, Y_test), graph_data = \\\n",
    "    load_20news(data_home='data', top_words=top_words, sparse=sparse,\n",
    "                remove_short_documents=remove_short_documents, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2])\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2])\n",
    "num_classes = Y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.29 s, sys: 739 ms, total: 3.03 s\n",
      "Wall time: 3.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Process next cell only once\n",
    "path = os.path.join('probabilities_' + \n",
    "                    'top' + str(top_words) +\n",
    "                    '_sparse' + str(sparse) +\n",
    "                    '_removeShorts' + str(remove_short_documents) +\n",
    "                    '.pkl')\n",
    "if os.path.isfile(path):\n",
    "  probabilities = pickle.load(open(path, \"rb\"), encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not(os.path.isfile(path)):\n",
    "  METRIC = 'cosine'#'euclidean'\n",
    "  distances = sk.metrics.pairwise.pairwise_distances(graph_data, metric=METRIC, n_jobs=-2)\n",
    "\n",
    "  # enforce exact zero\n",
    "  for k in xrange(distances.shape[0]):\n",
    "    distances[k,k] = 0.\n",
    "\n",
    "  # max normalize\n",
    "  #distances /= distances.max()\n",
    "  distances /= distances.max(axis=1).reshape((distances.shape[0], 1))\n",
    "\n",
    "  # use tricube kernel (becaause of flatness around 0)\n",
    "  probabilities = (1. - np.abs(distances) ** 3) ** 3\n",
    "\n",
    "  # remove auto connections (which are taken anyway in LRF)\n",
    "  for k in xrange(probabilities.shape[0]):\n",
    "    probabilities[k,k] = 0.\n",
    "\n",
    "  # normalize proba\n",
    "  probabilities /= np.sum(probabilities, axis=1).reshape((probabilities.shape[0], 1))\n",
    "  \n",
    "  # pickled for later use\n",
    "  pickle.dump(probabilities, open(path,\"wb\"))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "random_lrf_1 (RandomLRF)     (None, 10000, 25)         425       \n",
      "_________________________________________________________________\n",
      "random_lrf_2 (RandomLRF)     (None, 10000, 25)         10025     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 250000)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 250000)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                5000020   \n",
      "=================================================================\n",
      "Total params: 5,010,470\n",
      "Trainable params: 5,010,470\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "model = Sequential()\n",
    "model.add(RandomLRF(probabilities, LRF_size=16, filters=25, activation='relu',\n",
    "                       input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(RandomLRF(probabilities, LRF_size=16, filters=25, activation='relu',\n",
    "                       input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "#model.add(Conv1D(1, kernel_size=1, activation='relu',\n",
    "#                 padding='same',kernel_initializer='he_uniform'))\n",
    "#model.add(SeparableMonteCarloMaxPoolingV2(LRF_size=4, new_size=2500))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "#model.add(Dense(500, activation='relu'))\n",
    "model.add(Dropout(0.9))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10168 samples, validate on 7071 samples\n",
      "Epoch 1/100\n",
      "10168/10168 [==============================] - 27s 3ms/step - loss: 2.6814 - acc: 0.2787 - val_loss: 2.1871 - val_acc: 0.5506\n",
      "Epoch 2/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 1.3499 - acc: 0.6961 - val_loss: 1.3709 - val_acc: 0.6439\n",
      "Epoch 3/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.6877 - acc: 0.8159 - val_loss: 1.2831 - val_acc: 0.6669\n",
      "Epoch 4/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.4617 - acc: 0.8704 - val_loss: 1.3264 - val_acc: 0.6713\n",
      "Epoch 5/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.3491 - acc: 0.9002 - val_loss: 1.4042 - val_acc: 0.6672\n",
      "Epoch 6/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.2728 - acc: 0.9207 - val_loss: 1.4897 - val_acc: 0.6661\n",
      "Epoch 7/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.2264 - acc: 0.9345 - val_loss: 1.5806 - val_acc: 0.6587\n",
      "Epoch 8/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.1962 - acc: 0.9425 - val_loss: 1.6219 - val_acc: 0.6665\n",
      "Epoch 9/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.1817 - acc: 0.9452 - val_loss: 1.6910 - val_acc: 0.6685\n",
      "Epoch 10/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.1688 - acc: 0.9492 - val_loss: 1.8040 - val_acc: 0.6592\n",
      "Epoch 11/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.1569 - acc: 0.9535 - val_loss: 1.8355 - val_acc: 0.6603\n",
      "Epoch 12/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.1392 - acc: 0.9579 - val_loss: 1.8650 - val_acc: 0.6595\n",
      "Epoch 13/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.1333 - acc: 0.9599 - val_loss: 1.9139 - val_acc: 0.6660\n",
      "Epoch 14/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.1221 - acc: 0.9612 - val_loss: 1.9955 - val_acc: 0.6545\n",
      "Epoch 15/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.1078 - acc: 0.9661 - val_loss: 2.0723 - val_acc: 0.6583\n",
      "Epoch 16/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.1229 - acc: 0.9622 - val_loss: 2.0603 - val_acc: 0.6637\n",
      "Epoch 17/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.1127 - acc: 0.9648 - val_loss: 2.0820 - val_acc: 0.6603\n",
      "Epoch 18/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.1044 - acc: 0.9682 - val_loss: 2.1471 - val_acc: 0.6599\n",
      "Epoch 19/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.1052 - acc: 0.9673 - val_loss: 2.1290 - val_acc: 0.6623\n",
      "Epoch 20/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0999 - acc: 0.9696 - val_loss: 2.2285 - val_acc: 0.6569\n",
      "Epoch 21/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.1043 - acc: 0.9711 - val_loss: 2.2113 - val_acc: 0.6555\n",
      "Epoch 22/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0985 - acc: 0.9695 - val_loss: 2.1849 - val_acc: 0.6568\n",
      "Epoch 23/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0987 - acc: 0.9709 - val_loss: 2.3090 - val_acc: 0.6537\n",
      "Epoch 24/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0944 - acc: 0.9730 - val_loss: 2.2866 - val_acc: 0.6513\n",
      "Epoch 25/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0839 - acc: 0.9768 - val_loss: 2.3538 - val_acc: 0.6549\n",
      "Epoch 26/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0971 - acc: 0.9709 - val_loss: 2.3334 - val_acc: 0.6524\n",
      "Epoch 27/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0815 - acc: 0.9776 - val_loss: 2.3908 - val_acc: 0.6518\n",
      "Epoch 28/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0799 - acc: 0.9746 - val_loss: 2.3554 - val_acc: 0.6505\n",
      "Epoch 29/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0894 - acc: 0.9748 - val_loss: 2.4023 - val_acc: 0.6524\n",
      "Epoch 30/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0863 - acc: 0.9767 - val_loss: 2.3858 - val_acc: 0.6511\n",
      "Epoch 31/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0706 - acc: 0.9774 - val_loss: 2.5136 - val_acc: 0.6517\n",
      "Epoch 32/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0681 - acc: 0.9785 - val_loss: 2.4750 - val_acc: 0.6541\n",
      "Epoch 33/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0828 - acc: 0.9783 - val_loss: 2.4853 - val_acc: 0.6463\n",
      "Epoch 34/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0731 - acc: 0.9779 - val_loss: 2.4380 - val_acc: 0.6493\n",
      "Epoch 35/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0812 - acc: 0.9772 - val_loss: 2.3965 - val_acc: 0.6414\n",
      "Epoch 36/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0678 - acc: 0.9787 - val_loss: 2.5309 - val_acc: 0.6480\n",
      "Epoch 37/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0824 - acc: 0.9768 - val_loss: 2.4301 - val_acc: 0.6445\n",
      "Epoch 38/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0716 - acc: 0.9798 - val_loss: 2.5084 - val_acc: 0.6507\n",
      "Epoch 39/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0780 - acc: 0.9755 - val_loss: 2.5419 - val_acc: 0.6513\n",
      "Epoch 40/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0669 - acc: 0.9811 - val_loss: 2.5701 - val_acc: 0.6545\n",
      "Epoch 41/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0681 - acc: 0.9798 - val_loss: 2.5322 - val_acc: 0.6510\n",
      "Epoch 42/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0756 - acc: 0.9774 - val_loss: 2.5951 - val_acc: 0.6496\n",
      "Epoch 43/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0791 - acc: 0.9778 - val_loss: 2.5024 - val_acc: 0.6479\n",
      "Epoch 44/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0674 - acc: 0.9808 - val_loss: 2.5076 - val_acc: 0.6479\n",
      "Epoch 45/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0677 - acc: 0.9798 - val_loss: 2.5208 - val_acc: 0.6479\n",
      "Epoch 46/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0539 - acc: 0.9833 - val_loss: 2.5963 - val_acc: 0.6496\n",
      "Epoch 47/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0657 - acc: 0.9817 - val_loss: 2.6035 - val_acc: 0.6470\n",
      "Epoch 48/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0714 - acc: 0.9803 - val_loss: 2.7173 - val_acc: 0.6476\n",
      "Epoch 49/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0672 - acc: 0.9818 - val_loss: 2.6118 - val_acc: 0.6462\n",
      "Epoch 50/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0608 - acc: 0.9839 - val_loss: 2.6797 - val_acc: 0.6491\n",
      "Epoch 51/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0599 - acc: 0.9809 - val_loss: 2.4892 - val_acc: 0.6464\n",
      "Epoch 52/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0630 - acc: 0.9827 - val_loss: 2.5909 - val_acc: 0.6518\n",
      "Epoch 53/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0548 - acc: 0.9844 - val_loss: 2.6837 - val_acc: 0.6515\n",
      "Epoch 54/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0654 - acc: 0.9825 - val_loss: 2.6797 - val_acc: 0.6498\n",
      "Epoch 55/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0629 - acc: 0.9821 - val_loss: 2.5712 - val_acc: 0.6453\n",
      "Epoch 56/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0507 - acc: 0.9850 - val_loss: 2.6894 - val_acc: 0.6481\n",
      "Epoch 57/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0538 - acc: 0.9835 - val_loss: 2.7126 - val_acc: 0.6534\n",
      "Epoch 58/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0574 - acc: 0.9840 - val_loss: 2.8084 - val_acc: 0.6491\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0588 - acc: 0.9829 - val_loss: 2.7412 - val_acc: 0.6538\n",
      "Epoch 60/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0586 - acc: 0.9821 - val_loss: 2.6950 - val_acc: 0.6518\n",
      "Epoch 61/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0521 - acc: 0.9847 - val_loss: 2.7406 - val_acc: 0.6529\n",
      "Epoch 62/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0446 - acc: 0.9859 - val_loss: 2.6532 - val_acc: 0.6497\n",
      "Epoch 63/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0506 - acc: 0.9845 - val_loss: 2.7107 - val_acc: 0.6497\n",
      "Epoch 64/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0583 - acc: 0.9832 - val_loss: 2.6303 - val_acc: 0.6517\n",
      "Epoch 65/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0514 - acc: 0.9852 - val_loss: 2.6883 - val_acc: 0.6508\n",
      "Epoch 66/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0494 - acc: 0.9852 - val_loss: 2.7619 - val_acc: 0.6525\n",
      "Epoch 67/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0550 - acc: 0.9844 - val_loss: 2.7337 - val_acc: 0.6534\n",
      "Epoch 68/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0492 - acc: 0.9844 - val_loss: 2.7010 - val_acc: 0.6521\n",
      "Epoch 69/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0567 - acc: 0.9825 - val_loss: 2.5891 - val_acc: 0.6452\n",
      "Epoch 70/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0485 - acc: 0.9854 - val_loss: 2.7572 - val_acc: 0.6529\n",
      "Epoch 71/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0553 - acc: 0.9838 - val_loss: 2.6997 - val_acc: 0.6452\n",
      "Epoch 72/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0475 - acc: 0.9861 - val_loss: 2.7785 - val_acc: 0.6528\n",
      "Epoch 73/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0481 - acc: 0.9852 - val_loss: 2.6741 - val_acc: 0.6520\n",
      "Epoch 74/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0612 - acc: 0.9822 - val_loss: 2.7534 - val_acc: 0.6524\n",
      "Epoch 75/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0447 - acc: 0.9880 - val_loss: 2.7004 - val_acc: 0.6528\n",
      "Epoch 76/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0425 - acc: 0.9875 - val_loss: 2.7104 - val_acc: 0.6487\n",
      "Epoch 77/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0533 - acc: 0.9851 - val_loss: 2.7803 - val_acc: 0.6528\n",
      "Epoch 78/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0486 - acc: 0.9872 - val_loss: 2.8023 - val_acc: 0.6490\n",
      "Epoch 79/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0434 - acc: 0.9884 - val_loss: 2.7117 - val_acc: 0.6500\n",
      "Epoch 80/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0513 - acc: 0.9858 - val_loss: 2.7664 - val_acc: 0.6500\n",
      "Epoch 81/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0447 - acc: 0.9860 - val_loss: 2.6993 - val_acc: 0.6494\n",
      "Epoch 82/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0471 - acc: 0.9874 - val_loss: 2.7355 - val_acc: 0.6483\n",
      "Epoch 83/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0447 - acc: 0.9863 - val_loss: 2.7695 - val_acc: 0.6494\n",
      "Epoch 84/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0402 - acc: 0.9887 - val_loss: 2.7679 - val_acc: 0.6517\n",
      "Epoch 85/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0422 - acc: 0.9866 - val_loss: 2.7059 - val_acc: 0.6490\n",
      "Epoch 86/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0467 - acc: 0.9861 - val_loss: 2.8310 - val_acc: 0.6527\n",
      "Epoch 87/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0413 - acc: 0.9881 - val_loss: 2.8486 - val_acc: 0.6558\n",
      "Epoch 88/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0436 - acc: 0.9871 - val_loss: 2.8223 - val_acc: 0.6542\n",
      "Epoch 89/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0427 - acc: 0.9883 - val_loss: 2.8863 - val_acc: 0.6561\n",
      "Epoch 90/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0487 - acc: 0.9870 - val_loss: 2.8684 - val_acc: 0.6476\n",
      "Epoch 91/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0408 - acc: 0.9881 - val_loss: 2.7981 - val_acc: 0.6510\n",
      "Epoch 92/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0435 - acc: 0.9860 - val_loss: 2.8352 - val_acc: 0.6535\n",
      "Epoch 93/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0460 - acc: 0.9872 - val_loss: 2.7827 - val_acc: 0.6476\n",
      "Epoch 94/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0407 - acc: 0.9873 - val_loss: 2.8004 - val_acc: 0.6490\n",
      "Epoch 95/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0419 - acc: 0.9877 - val_loss: 2.8493 - val_acc: 0.6544\n",
      "Epoch 96/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0417 - acc: 0.9880 - val_loss: 2.8135 - val_acc: 0.6542\n",
      "Epoch 97/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0402 - acc: 0.9893 - val_loss: 2.8871 - val_acc: 0.6542\n",
      "Epoch 98/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0411 - acc: 0.9886 - val_loss: 2.8322 - val_acc: 0.6507\n",
      "Epoch 99/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0413 - acc: 0.9883 - val_loss: 2.8949 - val_acc: 0.6513\n",
      "Epoch 100/100\n",
      "10168/10168 [==============================] - 25s 2ms/step - loss: 0.0399 - acc: 0.9883 - val_loss: 2.8749 - val_acc: 0.6566\n",
      "Test loss: 2.8749232661722406\n",
      "Test accuracy: 0.6566256541221925\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stopper = EarlyStopping(min_delta=0.001, patience=2)\n",
    "csv = CSVLogger(notebook + '_log.csv')\n",
    "\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=100,\n",
    "                    verbose=1,\n",
    "                    #callbacks=[early_stopper, csv],\n",
    "                    validation_data=(X_test, Y_test))\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch,acc,loss,val_acc,val_loss\r\n",
      "0,0.5808418563836021,1.6425235706647487,0.6755762969043194,1.2167736569888654\r\n",
      "1,0.8869984262951897,0.4604991487777674,0.6921227553864885,1.169997093844761\r\n",
      "2,0.9468922109513842,0.22660820962264724,0.6907085280424465,1.215745747671018\r\n",
      "3,0.9761998427373795,0.12425905712869204,0.6724649974487573,1.3969360224311516\r\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "tail mcNet_top10k_temptative_42_log.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
