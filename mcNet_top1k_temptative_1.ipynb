{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, Dense, Dropout, Flatten\n",
    "\n",
    "from loader import load_20news\n",
    "from custom_layer import MonteCarloLRF\n",
    "\n",
    "import numpy as np\n",
    "import sklearn as sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(input_shape, nb_classes), (X_train, X_test, Y_train, Y_test), graph_data = \\\n",
    "    load_20news(data_home='data', top_words=1000, sparse=False, remove_short_documents=True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2])\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2])\n",
    "batch_size = 64\n",
    "num_classes = Y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9922, 1000, 1)\n",
      "(6695, 1000, 1)\n",
      "64 20\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(batch_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "METRIC = 'euclidean'\n",
    "distances = sk.metrics.pairwise.pairwise_distances(graph_data, metric=METRIC, n_jobs=-2)\n",
    "\n",
    "# enforce exact zero\n",
    "for k in xrange(distances.shape[0]):\n",
    "  distances[k,k] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# max normalize\n",
    "distances /= distances.max()\n",
    "\n",
    "# use tricube kernel (becaause of flatness around 0)\n",
    "probabilities = (1. - np.abs(distances) ** 3) ** 3\n",
    "\n",
    "# remove auto connections (which are taken anyway in LRF)\n",
    "for k in xrange(probabilities.shape[0]):\n",
    "  probabilities[k,k] = 0.\n",
    "\n",
    "# normalize proba\n",
    "probabilities /= np.sum(probabilities, axis=1).reshape((probabilities.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 1000, 64)          128       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "monte_carlo_lrf_1 (MonteCarl (None, 1000, 64)          1088      \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1000, 64)          4160      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "monte_carlo_lrf_2 (MonteCarl (None, 1000, 64)          1088      \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1000, 64)          4160      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 64000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                1280020   \n",
      "=================================================================\n",
      "Total params: 1,290,644\n",
      "Trainable params: 1,290,644\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(64, kernel_size=1, activation='relu',\n",
    "                 padding='same',kernel_initializer='he_uniform',\n",
    "                 input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(SeparableMonteCarloLRF(probabilities, LRF_size=16, activation='relu'))\n",
    "model.add(Conv1D(64, kernel_size=1, activation='relu',\n",
    "                 padding='same',kernel_initializer='he_uniform'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(SeparableMonteCarloLRF(probabilities, LRF_size=16, activation='relu'))\n",
    "model.add(Conv1D(64, kernel_size=1, activation='relu',\n",
    "                 padding='same',kernel_initializer='he_uniform'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9922 samples, validate on 6695 samples\n",
      "Epoch 1/20\n",
      "9922/9922 [==============================] - 60s - loss: 2.4232 - acc: 0.2991 - val_loss: 1.8613 - val_acc: 0.4796\n",
      "Epoch 2/20\n",
      "9922/9922 [==============================] - 59s - loss: 1.4194 - acc: 0.5972 - val_loss: 1.7020 - val_acc: 0.5144\n",
      "Epoch 3/20\n",
      "9922/9922 [==============================] - 59s - loss: 1.0990 - acc: 0.6759 - val_loss: 1.7479 - val_acc: 0.5223\n",
      "Epoch 4/20\n",
      "9922/9922 [==============================] - 59s - loss: 0.8993 - acc: 0.7259 - val_loss: 1.7302 - val_acc: 0.5373\n",
      "Epoch 5/20\n",
      "9922/9922 [==============================] - 59s - loss: 0.7542 - acc: 0.7649 - val_loss: 1.7987 - val_acc: 0.5525\n",
      "Epoch 6/20\n",
      "9922/9922 [==============================] - 59s - loss: 0.6377 - acc: 0.8029 - val_loss: 1.8577 - val_acc: 0.5298\n",
      "Epoch 7/20\n",
      "9922/9922 [==============================] - 59s - loss: 0.5341 - acc: 0.8315 - val_loss: 1.9870 - val_acc: 0.5395\n",
      "Epoch 8/20\n",
      "9922/9922 [==============================] - 59s - loss: 0.4395 - acc: 0.8644 - val_loss: 2.0799 - val_acc: 0.5301\n",
      "Epoch 9/20\n",
      "9922/9922 [==============================] - 59s - loss: 0.3791 - acc: 0.8843 - val_loss: 2.1776 - val_acc: 0.5298\n",
      "Epoch 10/20\n",
      "9922/9922 [==============================] - 59s - loss: 0.3126 - acc: 0.9042 - val_loss: 2.3036 - val_acc: 0.5407\n",
      "Epoch 11/20\n",
      "9922/9922 [==============================] - 59s - loss: 0.2537 - acc: 0.9232 - val_loss: 2.4528 - val_acc: 0.5347\n",
      "Epoch 12/20\n",
      "9922/9922 [==============================] - 59s - loss: 0.2154 - acc: 0.9375 - val_loss: 2.4967 - val_acc: 0.5461\n",
      "Epoch 13/20\n",
      "9922/9922 [==============================] - 59s - loss: 0.1831 - acc: 0.9471 - val_loss: 2.5265 - val_acc: 0.5404\n",
      "Epoch 14/20\n",
      "9922/9922 [==============================] - 59s - loss: 0.1772 - acc: 0.9486 - val_loss: 2.7090 - val_acc: 0.5237\n",
      "Epoch 15/20\n",
      "9922/9922 [==============================] - 59s - loss: 0.1732 - acc: 0.9504 - val_loss: 2.8021 - val_acc: 0.5377\n",
      "Epoch 16/20\n",
      "9922/9922 [==============================] - 59s - loss: 0.1365 - acc: 0.9617 - val_loss: 2.7490 - val_acc: 0.5382\n",
      "Epoch 17/20\n",
      "9922/9922 [==============================] - 59s - loss: 0.1167 - acc: 0.9677 - val_loss: 2.8329 - val_acc: 0.5373\n",
      "Epoch 18/20\n",
      "9922/9922 [==============================] - 59s - loss: 0.0966 - acc: 0.9722 - val_loss: 2.9679 - val_acc: 0.5368\n",
      "Epoch 19/20\n",
      "9922/9922 [==============================] - 59s - loss: 0.0859 - acc: 0.9778 - val_loss: 2.8772 - val_acc: 0.5377\n",
      "Epoch 20/20\n",
      "9922/9922 [==============================] - 59s - loss: 0.0896 - acc: 0.9763 - val_loss: 2.9810 - val_acc: 0.5416\n",
      "Test loss: 2.98098041671\n",
      "Test accuracy: 0.541598207631\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=20,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, Y_test))\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pvle",
   "language": "python",
   "name": "pvle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
